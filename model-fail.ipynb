{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRCP</th>\n",
       "      <th>SNOW</th>\n",
       "      <th>TAVG</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DATE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1900-01</th>\n",
       "      <td>0.69</td>\n",
       "      <td>4.5</td>\n",
       "      <td>23.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1900-02</th>\n",
       "      <td>1.26</td>\n",
       "      <td>9.1</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1900-03</th>\n",
       "      <td>1.33</td>\n",
       "      <td>12.5</td>\n",
       "      <td>25.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1900-04</th>\n",
       "      <td>1.31</td>\n",
       "      <td>5.0</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1900-05</th>\n",
       "      <td>1.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-09</th>\n",
       "      <td>5.19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10</th>\n",
       "      <td>5.98</td>\n",
       "      <td>5.6</td>\n",
       "      <td>48.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11</th>\n",
       "      <td>3.17</td>\n",
       "      <td>9.2</td>\n",
       "      <td>29.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12</th>\n",
       "      <td>1.75</td>\n",
       "      <td>1.2</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01</th>\n",
       "      <td>1.92</td>\n",
       "      <td>14.7</td>\n",
       "      <td>24.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25271 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         PRCP  SNOW  TAVG\n",
       "DATE                     \n",
       "1900-01  0.69   4.5  23.7\n",
       "1900-02  1.26   9.1  13.0\n",
       "1900-03  1.33  12.5  25.1\n",
       "1900-04  1.31   5.0  48.0\n",
       "1900-05  1.87   0.0  60.5\n",
       "...       ...   ...   ...\n",
       "2019-09  5.19   0.0  65.4\n",
       "2019-10  5.98   5.6  48.3\n",
       "2019-11  3.17   9.2  29.4\n",
       "2019-12  1.75   1.2  29.0\n",
       "2020-01  1.92  14.7  24.9\n",
       "\n",
       "[25271 rows x 3 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preliminaries\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from numpy import loadtxt\n",
    "from numpy import nan\n",
    "from numpy import isnan\n",
    "from numpy import count_nonzero\n",
    "from numpy import unique\n",
    "from numpy import array\n",
    "from numpy import nanmedian\n",
    "from numpy import save\n",
    "from sktime.classification.interval_based import TimeSeriesForestClassifier\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# load data and fix issues w original\n",
    "\n",
    "weather = pd.read_csv('madweather.csv')\n",
    "del weather['Unnamed: 0']\n",
    "weather.head()\n",
    "#weather.dtypes\n",
    "\n",
    "# change data from object to datetime\n",
    "weather['DATE'] = pd.to_datetime(weather.DATE, format = '%Y/%m')\n",
    "data = weather.drop(['DATE'], axis = 1)\n",
    "data.index = pd.DatetimeIndex(weather.DATE).to_period('m')\n",
    "\n",
    "\n",
    "data = data.fillna(method=\"ffill\")\n",
    "data = data.iloc[0:,0:3]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = data.values\n",
    "# get list of unique chunk identifiers\n",
    "chunk_ids = unique(values[:,1])\n",
    "\n",
    "chunks = dict()\n",
    "\n",
    "\n",
    "# split the dataset by 'chunkID', return a list of chunks\n",
    "def to_chunks(values, chunk_ix=0):\n",
    "\tchunks = list()\n",
    "\t# get the unique chunk ids\n",
    "\tchunk_ids = unique(values[:, chunk_ix])\n",
    "\t# group rows by chunk id\n",
    "\tfor chunk_id in chunk_ids:\n",
    "\t\tselection = values[:, chunk_ix] == chunk_id\n",
    "\t\tchunks.append(values[selection, :])\n",
    "\treturn chunks\n",
    " \n",
    "# return a list of relative forecast lead times\n",
    "def get_lead_times():\n",
    "\treturn [1, 2, 3, 4, 5, 10, 17, 24, 48, 72]\n",
    " \n",
    "# interpolate series of hours (in place) in 24 hour time\n",
    "def interpolate_hours(hours):\n",
    "\t# find the first hour\n",
    "\tix = -1\n",
    "\tfor i in range(len(hours)):\n",
    "\t\tif not isnan(hours[i]):\n",
    "\t\t\tix = i\n",
    "\t\t\tbreak\n",
    "\t# fill-forward\n",
    "\thour = hours[ix]\n",
    "\tfor i in range(ix+1, len(hours)):\n",
    "\t\t# increment hour\n",
    "\t\thour += 1\n",
    "\t\t# check for a fill\n",
    "\t\tif isnan(hours[i]):\n",
    "\t\t\thours[i] = hour % 24\n",
    "\t# fill-backward\n",
    "\thour = hours[ix]\n",
    "\tfor i in range(ix-1, -1, -1):\n",
    "\t\t# decrement hour\n",
    "\t\thour -= 1\n",
    "\t\t# check for a fill\n",
    "\t\tif isnan(hours[i]):\n",
    "\t\t\thours[i] = hour % 24\n",
    " \n",
    "# return true if the array has any non-nan values\n",
    "def has_data(data):\n",
    "\treturn count_nonzero(isnan(data)) < len(data)\n",
    " \n",
    "# impute missing data\n",
    "def impute_missing(train_chunks, rows, hours, series, col_ix):\n",
    "\t# impute missing using the median value for hour in all series\n",
    "\timputed = list()\n",
    "\tfor i in range(len(series)):\n",
    "\t\tif isnan(series[i]):\n",
    "\t\t\t# collect all rows across all chunks for the hour\n",
    "\t\t\tall_rows = list()\n",
    "\t\t\tfor rows in train_chunks:\n",
    "\t\t\t\t[all_rows.append(row) for row in rows[rows[:,2]==hours[i]]]\n",
    "\t\t\t# calculate the central tendency for target\n",
    "\t\t\tall_rows = array(all_rows)\n",
    "\t\t\t# fill with median value\n",
    "\t\t\tvalue = nanmedian(all_rows[:, col_ix])\n",
    "\t\t\tif isnan(value):\n",
    "\t\t\t\tvalue = 0.0\n",
    "\t\t\timputed.append(value)\n",
    "\t\telse:\n",
    "\t\t\timputed.append(series[i])\n",
    "\treturn imputed\n",
    " \n",
    "# layout a variable with breaks in the data for missing positions\n",
    "def variable_to_series(chunk_train, col_ix, n_steps=5*24):\n",
    "\t# lay out whole series\n",
    "\tdata = [nan for _ in range(n_steps)]\n",
    "\t# mark all available data\n",
    "\tfor i in range(len(chunk_train)):\n",
    "\t\t# get position in chunk\n",
    "\t\tposition = int(chunk_train[i, 1] - 1)\n",
    "\t\t# store data\n",
    "\t\tdata[position] = chunk_train[i, col_ix]\n",
    "\treturn data\n",
    " \n",
    "# created input/output patterns from a sequence\n",
    "def supervised_for_lead_time(series, n_lag, lead_time):\n",
    "\tsamples = list()\n",
    "\t# enumerate observations and create input/output patterns\n",
    "\tfor i in range(n_lag, len(series)):\n",
    "\t\tend_ix = i + (lead_time - 1)\n",
    "\t\t# check if can create a pattern\n",
    "\t\tif end_ix >= len(series):\n",
    "\t\t\tbreak\n",
    "\t\t# retrieve input and output\n",
    "\t\tstart_ix = i - n_lag\n",
    "\t\trow = series[start_ix:i] + [series[end_ix]]\n",
    "\t\tsamples.append(row)\n",
    "\treturn samples\n",
    " \n",
    "# create supervised learning data for each lead time for this target\n",
    "def target_to_supervised(chunks, rows, hours, col_ix, n_lag):\n",
    "\ttrain_lead_times = list()\n",
    "\t# get series\n",
    "\tseries = variable_to_series(rows, col_ix)\n",
    "\tif not has_data(series):\n",
    "\t\treturn None, [nan for _ in range(n_lag)]\n",
    "\t# impute\n",
    "\timputed = impute_missing(chunks, rows, hours, series, col_ix)\n",
    "\t# prepare test sample for chunk-variable\n",
    "\ttest_sample = array(imputed[-n_lag:])\n",
    "\t# enumerate lead times\n",
    "\tlead_times = get_lead_times()\n",
    "\tfor lead_time in lead_times:\n",
    "\t\t# make input/output data from series\n",
    "\t\ttrain_samples = supervised_for_lead_time(imputed, n_lag, lead_time)\n",
    "\t\ttrain_lead_times.append(train_samples)\n",
    "\treturn train_lead_times, test_sample\n",
    " \n",
    "# prepare training [var][lead time][sample] and test [chunk][var][sample]\n",
    "def data_prep(chunks, n_lag, n_vars=39):\n",
    "\tlead_times = get_lead_times()\n",
    "\ttrain_data = [[list() for _ in range(len(lead_times))] for _ in range(n_vars)]\n",
    "\ttest_data = [[list() for _ in range(n_vars)] for _ in range(len(chunks))]\n",
    "\t# enumerate targets for chunk\n",
    "\tfor var in range(n_vars):\n",
    "\t\t# convert target number into column number\n",
    "\t\tcol_ix = 3 + var\n",
    "\t\t# enumerate chunks to forecast\n",
    "\t\tfor c_id in range(len(chunks)):\n",
    "\t\t\trows = chunks[c_id]\n",
    "\t\t\t# prepare sequence of hours for the chunk\n",
    "\t\t\thours = variable_to_series(rows, 2)\n",
    "\t\t\t# interpolate hours\n",
    "\t\t\tinterpolate_hours(hours)\n",
    "\t\t\t# check for no data\n",
    "\t\t\tif not has_data(rows[:, col_ix]):\n",
    "\t\t\t\tcontinue\n",
    "\t\t\t# convert series into training data for each lead time\n",
    "\t\t\ttrain, test_sample = target_to_supervised(chunks, rows, hours, col_ix, n_lag)\n",
    "\t\t\t# store test sample for this var-chunk\n",
    "\t\t\ttest_data[c_id][var] = test_sample\n",
    "\t\t\tif train is not None:\n",
    "\t\t\t\t# store samples per lead time\n",
    "\t\t\t\tfor lead_time in range(len(lead_times)):\n",
    "\t\t\t\t\t# add all rows to the existing list of rows\n",
    "\t\t\t\t\ttrain_data[var][lead_time].extend(train[lead_time])\n",
    "\t\t# convert all rows for each var-lead time to a numpy array\n",
    "\t\tfor lead_time in range(len(lead_times)):\n",
    "\t\t\ttrain_data[var][lead_time] = array(train_data[var][lead_time])\n",
    "\treturn array(train_data), array(test_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.69,  4.5 , 23.7 ],\n",
       "       [ 1.26,  9.1 , 13.  ],\n",
       "       [ 1.33, 12.5 , 25.1 ],\n",
       "       ...,\n",
       "       [ 0.  ,  0.1 , 23.6 ],\n",
       "       [ 0.  ,  0.  , 23.6 ],\n",
       "       [ 0.  ,  0.  , 23.6 ]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.to_numpy\n",
    "data.iloc[:int(data.shape[0]*0.7)].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 3 is out of bounds for axis 1 with size 3",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-0fdf70144288>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m# convert training data into supervised learning data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mn_lag\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m12\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_prep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_chunks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_lag\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;31m# save train and test sets to file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-25-5ac07364f477>\u001b[0m in \u001b[0;36mdata_prep\u001b[1;34m(chunks, n_lag, n_vars)\u001b[0m\n\u001b[0;32m    134\u001b[0m                         \u001b[0minterpolate_hours\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhours\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m                         \u001b[1;31m# check for no data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 136\u001b[1;33m                         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhas_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrows\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol_ix\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    137\u001b[0m                                 \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m                         \u001b[1;31m# convert series into training data for each lead time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 3 is out of bounds for axis 1 with size 3"
     ]
    }
   ],
   "source": [
    "# split into test and train\n",
    "from sklearn.model_selection import train_test_split\n",
    "train = data.iloc[:int(data.shape[0]*0.7)].values\n",
    "test = data.iloc[int(data.shape[0]*0.7):].values\n",
    "\n",
    "# group data by chunks\n",
    "values = data.values\n",
    "chunks = to_chunks(values)\n",
    "\n",
    "# group data by chunks\n",
    "train_chunks = to_chunks(train)\n",
    "test_chunks = to_chunks(test)\n",
    "\n",
    "# convert training data into supervised learning data\n",
    "n_lag = 12\n",
    "train_data, test_data = data_prep(train_chunks, n_lag)\n",
    "print(train_data.shape, test_data.shape)\n",
    "# save train and test sets to file\n",
    "save('weatherPrediction/supervised_train.npy', train_data)\n",
    "save('weatherPrediction/supervised_test.npy', test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRCP</th>\n",
       "      <th>SNOW</th>\n",
       "      <th>TAVG</th>\n",
       "      <th>TMAX</th>\n",
       "      <th>TMIN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DATE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1900-01</th>\n",
       "      <td>0.69</td>\n",
       "      <td>4.5</td>\n",
       "      <td>23.7</td>\n",
       "      <td>30.8</td>\n",
       "      <td>16.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1900-02</th>\n",
       "      <td>1.26</td>\n",
       "      <td>9.1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>21.5</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1900-03</th>\n",
       "      <td>1.33</td>\n",
       "      <td>12.5</td>\n",
       "      <td>25.1</td>\n",
       "      <td>32.3</td>\n",
       "      <td>17.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1900-04</th>\n",
       "      <td>1.31</td>\n",
       "      <td>5.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>57.8</td>\n",
       "      <td>38.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1900-05</th>\n",
       "      <td>1.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.5</td>\n",
       "      <td>70.9</td>\n",
       "      <td>50.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         PRCP  SNOW  TAVG  TMAX  TMIN\n",
       "DATE                                 \n",
       "1900-01  0.69   4.5  23.7  30.8  16.6\n",
       "1900-02  1.26   9.1  13.0  21.5   4.5\n",
       "1900-03  1.33  12.5  25.1  32.3  17.9\n",
       "1900-04  1.31   5.0  48.0  57.8  38.3\n",
       "1900-05  1.87   0.0  60.5  70.9  50.2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b6888fb162843f7d73ce3845354ef50bb134704a8c892b747869d23492873ce9"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit (conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
